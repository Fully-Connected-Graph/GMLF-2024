{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Directories\n",
    "feature_importance_dir = (\n",
    "    \"/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/feature importances\"\n",
    ")\n",
    "data_processed_dir = (\n",
    "    \"/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/processed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of importance CSV files\n",
    "importance_files = [\n",
    "    f\n",
    "    for f in os.listdir(feature_importance_dir)\n",
    "    if f.endswith(\".csv\") and f.startswith(\"importance_\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/processed/funct_full_submit.csv\n",
      "/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/processed/reciprocal_features_submit.csv\n",
      "/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/processed/tsfresh_scaled_full_submit.csv\n",
      "/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/processed/quantile_features_submit.csv\n",
      "/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/processed/inter_features_submit.csv\n",
      "/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/processed/arcsinh_features_submit.csv\n",
      "/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/processed/poly_features_submit.csv\n",
      "/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/processed/pca_features_submit.csv\n",
      "/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/processed/exp_features_submit.csv\n",
      "/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/processed/log_features_submit.csv\n",
      "/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/processed/pca7_features_submit.csv\n",
      "/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/processed/tsfresh_full_submit.csv\n",
      "/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/processed/identity_features_submit.csv\n",
      "/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/processed/ln_features_submit.csv\n",
      "/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/processed/pwr3_features_submit.csv\n",
      "/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/processed/sqrt_features_submit.csv\n",
      "/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/processed/cbrt_features_submit.csv\n",
      "/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/processed/powertrans_features_submit.csv\n",
      "/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/processed/spline_features_submit.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Directories\n",
    "feature_importance_dir = (\n",
    "    \"/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/feature importances\"\n",
    ")\n",
    "data_processed_dir = (\n",
    "    \"/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/processed\"\n",
    ")\n",
    "\n",
    "# Get list of importance CSV files\n",
    "importance_files = [\n",
    "    f\n",
    "    for f in os.listdir(feature_importance_dir)\n",
    "    if f.endswith(\".csv\") and f.startswith(\"importance_\")\n",
    "]\n",
    "\n",
    "# Initialize final DataFrames\n",
    "final_df = pd.DataFrame()\n",
    "final_df_submit = pd.DataFrame()\n",
    "\n",
    "for imp_file in importance_files:\n",
    "    # Get the corresponding data file name by removing 'importance_' prefix\n",
    "    data_file_name = imp_file.replace(\"importance_\", \"\")\n",
    "\n",
    "    # Build full paths\n",
    "    imp_file_path = os.path.join(feature_importance_dir, imp_file)\n",
    "    data_file_path = os.path.join(data_processed_dir, data_file_name)\n",
    "\n",
    "    # Also build the '_submit.csv' version\n",
    "    base_name = os.path.splitext(data_file_name)[0]  # Remove '.csv' extension\n",
    "    submit_data_file_name = base_name + \"_submit.csv\"\n",
    "    submit_data_file_path = os.path.join(data_processed_dir, submit_data_file_name)\n",
    "\n",
    "    # Check if the data file exists\n",
    "    if not os.path.exists(data_file_path):\n",
    "        print(f\"Data file {data_file_name} does not exist, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Read the importance CSV\n",
    "    imp_df = pd.read_csv(imp_file_path)\n",
    "    # Get the list of features from 'Unnamed: 0' column\n",
    "    features = imp_df[\"Unnamed: 0\"].tolist()\n",
    "    features = [str(feature) for feature in features]\n",
    "    # Read the data CSV\n",
    "    data_df = pd.read_csv(data_file_path)\n",
    "\n",
    "    # Filter out the required features\n",
    "    selected_features_df = data_df[features]\n",
    "\n",
    "    # Make the column names unique by combining with the data_file_name (without .csv)\n",
    "    new_column_names = [f\"{base_name}_{col}\" for col in selected_features_df.columns]\n",
    "    selected_features_df.columns = new_column_names\n",
    "\n",
    "    # Combine with final_df\n",
    "    if final_df.empty:\n",
    "        final_df = selected_features_df\n",
    "    else:\n",
    "        final_df = pd.concat([final_df, selected_features_df], axis=1)\n",
    "\n",
    "    # Now process the '_submit.csv' file if it exists\n",
    "    if os.path.exists(submit_data_file_path):\n",
    "        # Read the submit data CSV\n",
    "        submit_data_df = pd.read_csv(submit_data_file_path)\n",
    "        # Filter out the required features\n",
    "        print(submit_data_file_path)\n",
    "        if submit_data_file_path == \"/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/processed/tsfresh_scaled_full_submit.csv\":\n",
    "            submit_data_df['Unnamed: 0'] = None\n",
    "        selected_submit_features_df = submit_data_df[features]\n",
    "\n",
    "        # Use the same unique column names\n",
    "        selected_submit_features_df.columns = new_column_names\n",
    "\n",
    "        # Combine with final_df_submit\n",
    "        if final_df_submit.empty:\n",
    "            final_df_submit = selected_submit_features_df\n",
    "        else:\n",
    "            final_df_submit = pd.concat(\n",
    "                [final_df_submit, selected_submit_features_df], axis=1\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final DataFrames\n",
    "output_file_path = (\n",
    "    \"/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/final_dataframe.csv\"\n",
    ")\n",
    "final_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "output_submit_file_path = \"/Users/akseljoonas/Documents/mlfortnight/mlfortnight_mine/data/final_dataframe_submit.csv\"\n",
    "final_df_submit.to_csv(output_submit_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlfortnight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
